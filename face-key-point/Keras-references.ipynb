{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from pandas.io.parsers import read_csv\n",
    "\n",
    "FTRAIN = 'training.csv'\n",
    "FTEST = 'test.csv'\n",
    "\n",
    "\n",
    "def load(test=False, cols=None):\n",
    "    '''Loads data from FTEST if *test* is True, otherwise from FTRAIN.\n",
    "    Pass a list of *cols* if you're only interested in a subset of the\n",
    "    target columns.\n",
    "    '''\n",
    "    fname = FTEST if test else FTRAIN\n",
    "    df = read_csv(os.path.expanduser(fname))  # load pandas dataframe\n",
    "\n",
    "    # The Image column has pixel values separated by space; convert\n",
    "    # the values to numpy arrays:\n",
    "    df['Image'] = df['Image'].apply(lambda im: np.fromstring(im, sep=' '))\n",
    "\n",
    "    if cols:  # get a subset of columns\n",
    "        df = df[list(cols) + ['Image']]\n",
    "\n",
    "    # print(df.count())  # prints the number of values for each column\n",
    "    df = df.dropna()  # drop all rows that have missing values in them\n",
    "\n",
    "    X = np.vstack(df['Image'].values) / 255.  # scale pixel values to [0, 1]\n",
    "    X = X.astype(np.float32)\n",
    "\n",
    "    if not test:  # only FTRAIN has any target columns\n",
    "        y = df[df.columns[:-1]].values\n",
    "        y = (y - 48) / 48  # scale target coordinates to [-1, 1]\n",
    "        X, y = shuffle(X, y, random_state=42)  # shuffle train data\n",
    "        y = y.astype(np.float32)\n",
    "    else:\n",
    "        y = None\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def load2d(test=False, cols=None):\n",
    "    X, y = load(test=test, cols=cols)\n",
    "    X = X.reshape(-1, 1, 96, 96)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'input_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-11cb44106834>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0minput_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload2d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'input_data'"
     ]
    }
   ],
   "source": [
    "# coding:utf-8\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from input_data import load2d\n",
    "from collections import OrderedDict\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# If you use gpu when using theano backend\n",
    "# import theano\n",
    "# theano.config.device = 'gpu'\n",
    "# theano.config.floatX = 'float32'\n",
    "\n",
    "SPECIALIST_SETTINGS = [\n",
    "    dict(\n",
    "        columns=(\n",
    "            'left_eye_center_x', 'left_eye_center_y',\n",
    "            'right_eye_center_x', 'right_eye_center_y',\n",
    "        ),\n",
    "        flip_indices=((0, 2), (1, 3)),\n",
    "    ),\n",
    "\n",
    "    dict(\n",
    "        columns=(\n",
    "            'nose_tip_x', 'nose_tip_y',\n",
    "        ),\n",
    "        flip_indices=(),\n",
    "    ),\n",
    "\n",
    "    dict(\n",
    "        columns=(\n",
    "            'mouth_left_corner_x', 'mouth_left_corner_y',\n",
    "            'mouth_right_corner_x', 'mouth_right_corner_y',\n",
    "            'mouth_center_top_lip_x', 'mouth_center_top_lip_y',\n",
    "        ),\n",
    "        flip_indices=((0, 2), (1, 3)),\n",
    "    ),\n",
    "\n",
    "    dict(\n",
    "        columns=(\n",
    "            'mouth_center_bottom_lip_x',\n",
    "            'mouth_center_bottom_lip_y',\n",
    "        ),\n",
    "        flip_indices=(),\n",
    "    ),\n",
    "\n",
    "    dict(\n",
    "        columns=(\n",
    "            'left_eye_inner_corner_x', 'left_eye_inner_corner_y',\n",
    "            'right_eye_inner_corner_x', 'right_eye_inner_corner_y',\n",
    "            'left_eye_outer_corner_x', 'left_eye_outer_corner_y',\n",
    "            'right_eye_outer_corner_x', 'right_eye_outer_corner_y',\n",
    "        ),\n",
    "        flip_indices=((0, 2), (1, 3), (4, 6), (5, 7)),\n",
    "    ),\n",
    "\n",
    "    dict(\n",
    "        columns=(\n",
    "            'left_eyebrow_inner_end_x', 'left_eyebrow_inner_end_y',\n",
    "            'right_eyebrow_inner_end_x', 'right_eyebrow_inner_end_y',\n",
    "            'left_eyebrow_outer_end_x', 'left_eyebrow_outer_end_y',\n",
    "            'right_eyebrow_outer_end_x', 'right_eyebrow_outer_end_y',\n",
    "        ),\n",
    "        flip_indices=((0, 2), (1, 3), (4, 6), (5, 7)),\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "class FlippedImageDataGenerator(ImageDataGenerator):\n",
    "    flip_indices = [(0, 2), (1, 3), (4, 8), (5, 9),\n",
    "                    (6, 10), (7, 11), (12, 16), (13, 17),\n",
    "                    (14, 18), (15, 19), (22, 24), (23, 25)]\n",
    "\n",
    "    def next(self):\n",
    "        X_batch, y_batch = super(FlippedImageDataGenerator, self).next()\n",
    "        batch_size = X_batch.shape[0]\n",
    "        indices = np.random.choice(batch_size, batch_size / 2, replace=False)\n",
    "        X_batch[indices] = X_batch[indices, :, :, ::-1]\n",
    "\n",
    "        if y_batch is not None:\n",
    "            y_batch[indices, ::2] = y_batch[indices, ::2] * -1\n",
    "\n",
    "            for a, b in self.flip_indices:\n",
    "                y_batch[indices, a], y_batch[indices, b] = (\n",
    "                    y_batch[indices, b], y_batch[indices, a]\n",
    "                )\n",
    "\n",
    "        return X_batch, y_batch\n",
    "\n",
    "\n",
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution2D(32, 3, 3, input_shape=(1, 96, 96)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Convolution2D(64, 2, 2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Convolution2D(128, 2, 2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1000))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1000))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(30))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def fit_model():\n",
    "    start = 0.03\n",
    "    stop = 0.001\n",
    "    nb_epoch = 10000\n",
    "    PRETRAIN = False\n",
    "    learning_rate = np.linspace(start, stop, nb_epoch)\n",
    "\n",
    "    X, y = load2d()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                test_size=0.2, random_state=42)\n",
    "\n",
    "    model = cnn_model()\n",
    "    if PRETRAIN:\n",
    "        model.load_weights('my_cnn_model_weights.h5')\n",
    "    sgd = SGD(lr=start, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='mse', optimizer=sgd)\n",
    "    change_lr = LearningRateScheduler(lambda epoch: float(learning_rate[epoch]))\n",
    "    early_stop = EarlyStopping(patience=100)\n",
    "\n",
    "    flipgen = FlippedImageDataGenerator()\n",
    "    hist = model.fit_generator(flipgen.flow(X_train, y_train),\n",
    "                            samples_per_epoch=X_train.shape[0],\n",
    "                            nb_epoch=nb_epoch,\n",
    "                            validation_data=(X_test, y_test),\n",
    "                            callbacks=[change_lr, early_stop])\n",
    "\n",
    "    model.save_weights('my_cnn_model_weights.h5', overwrite=True)\n",
    "    np.savetxt('my_cnn_model_loss.csv', hist.history['loss'])\n",
    "    np.savetxt('my_cnn_model_val_loss.csv', hist.history['val_loss'])\n",
    "\n",
    "\n",
    "def fit_specialists():\n",
    "    specialists = OrderedDict()\n",
    "    start = 0.03\n",
    "    stop = 0.001\n",
    "    nb_epoch = 10000\n",
    "    PRETRAIN = False\n",
    "    learning_rate = np.linspace(start, stop, nb_epoch)\n",
    "\n",
    "    for setting in SPECIALIST_SETTINGS:\n",
    "        cols = setting['columns']\n",
    "        X, y = load2d(cols=cols)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                test_size=0.2, random_state=42)\n",
    "        model = cnn_model()\n",
    "        if PRETRAIN:\n",
    "            model.load_weights('my_cnn_model_weights.h5')\n",
    "        model.layers.pop()\n",
    "        model.outputs = [model.layers[-1].output]\n",
    "        model.layers[-1].outbound_nodes = []\n",
    "        model.add(Dense(len(cols)))\n",
    "\n",
    "        sgd = SGD(lr=start, momentum=0.9, nesterov=True)\n",
    "        model.compile(loss='mse', optimizer=sgd)\n",
    "        lr_decay = LearningRateScheduler(lambda epoch: float(learning_rate[epoch]))\n",
    "        early_stop = EarlyStopping(patience=100)\n",
    "\n",
    "        flipgen = FlippedImageDataGenerator()\n",
    "        flipgen.flip_indices = setting['flip_indices']\n",
    "\n",
    "        print('Training model for columns {} for {} epochs'.format(cols, nb_epoch))\n",
    "\n",
    "        hist = model.fit_generator(flipgen.flow(X_train, y_train),\n",
    "                                samples_per_epoch=X_train.shape[0],\n",
    "                                nb_epoch=nb_epoch,\n",
    "                                validation_data=(X_test, y_test),\n",
    "                                callbacks=[lr_decay, early_stop])\n",
    "\n",
    "        model.save_weights('my_cnn_model_{}_weights.h5'.format(cols[0]))\n",
    "        np.savetxt('my_cnn_model_{}_loss.csv'.format(cols[0]), hist.history['loss'])\n",
    "        np.savetxt('my_cnn_model_{}_val_loss.csv'.format(cols[0]), hist.history['val_loss'])\n",
    "\n",
    "        specialists[cols] = model\n",
    "\n",
    "\n",
    "def plot_loss():\n",
    "    loss = np.loadtxt('my_cnn_model_loss.csv')\n",
    "    val_loss = np.loadtxt('my_cnn_model_val_loss.csv')\n",
    "\n",
    "    plt.plot(loss, linewidth=3, label='train')\n",
    "    plt.plot(val_loss, linewidth=3, label='valid')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.ylim(1e-3, 1e-2)\n",
    "    plt.yscale('log')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main():\n",
    "    fit_model()\n",
    "    fit_specialists()\n",
    "\n",
    "    # plot_loss()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
